# -*- coding: utf-8 -*-
"""BDA_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jDtysZdiAH9GYn5Vk0a3jJAvS0oIcOHj
"""

! pip install pyspark

from google.colab import drive
drive.mount('/content/drive')

from pyspark.sql.functions import round,avg
from pyspark.sql.types import FloatType,StringType
from pyspark.sql.functions import asc,col
from pyspark.sql import functions as F

from pyspark.sql import SparkSession
spark=SparkSession.builder.appName("Book Recommendation").config("spark.sql.analyzer.failAmbiguousSelfJoin", "false").getOrCreate()

import pandas as pd
df=pd.read_csv('/content/drive/MyDrive/BookReview.csv')
df.head()

df1=spark.createDataFrame(df)
df1.show()

"""# ACTION AND TRANSFORMATIONS"""

# printSchema() to view the schema of the dataframe
df1.printSchema()

# first() to display the first record in the dataframe
df1.first()

# limit() to display only the number records specified
df1.limit(2).show()

# take() to display the number of records specified in form of a list
df1.take(4)

# getNumPartitions() to get the total number of partitions
df1.rdd.getNumPartitions()

# repartition() to change the number of partitions
df2=df1.repartition(5)
df2.rdd.getNumPartitions()

# coalesce() to change the number of partitions
df3=df2.coalesce(3)
df3.rdd.getNumPartitions()

# select() to choose only the columns specified
new_df=df1.select("user_id","book_title","book_author","rating","publisher","year_of_publication")
new_df.show()

new_df.printSchema()

# count() to find the number of users each book has
book_df=df1.groupBy("book_title").count()
book_df=book_df.withColumnRenamed("count","number of users")
book_df.show(10,truncate=False)

# groupBy() to group the data based on author and provide the minimum rating obtained by that author
new_df.groupBy("book_author").min("rating").show(7)

# groupBy() to group the data based on author and provide the maximum rating obtained by that author
new_df.groupBy("book_author").max("rating").show(7)

#drop() to delete a single column
df=df1.drop("Unnamed: 0")
df.columns

# drop() to delete multiple columns
cols=['img_s','img_m','img_l']
df=df.drop(*cols)
df.columns

# distinct() to obtain unique plublishers
df.select("publisher").distinct().show(25,False)

# distinct() and count() to obtain unique publishers
df.select("publisher").distinct().count()

# agg() and avg() to find the average rating of each book
bk_df=df.groupBy('book_title').agg(round(avg("rating"),1)).withColumnRenamed("round(avg(rating), 1)","avg_rating")
bk_df=bk_df.withColumn("avg_rating",bk_df["avg_rating"].cast(FloatType()))
bk_df.show(25,truncate=False)

# filter() to obtain the list of authors with average rating above 8
bk_df.filter(bk_df['avg_rating']>8).show(10,truncate=False)

# groupBy() and count() to obtain the number of users of each book
bk_df1=df.groupBy('book_title').count()
bk_df1.show(10)

# join() to display the count of books published and average rating of each author
bk_df.join(bk_df1,bk_df.book_title==bk_df1.book_title).show()

# filter() to filter books published after 2000 into one dataframe and books with more than 8.0 rating to another dataframe
left_df=new_df.filter(df["year_of_publication"]>2000)
right_df=new_df.filter(df["rating"]>8.0)

# intersect() to find the books that were published after 2000 and has rating more than 8.0
in_df=left_df.intersect(right_df)
in_df.show()

# union() to find the books that were published either after 2000 or has more than 8.0 rating
un_df=left_df.union(right_df)
un_df.show()

# subtract() to find the books that were published after 2000 and has rating less than 8.0
sb_df=left_df.subtract(right_df)
sb_df.show()

# sample() to create a sample from the original dataframe
sample_df=df.sample(withReplacement=True,fraction=0.2,seed=1)
sample_df.show(5)
print('Sample size:',sample_df.count())

"""# SPARK SQL"""

# Creation of temp view table
df.createTempView("book")

# SQL query to view the table
spark.sql("select * from book").show(5)

# SSQL query to view distinct values of cattegory column
spark.sql("select distinct Category from book").show(25,False)

# SQL query to choose books under fiction category
spark.sql("select user_id,book_title,Category from book where Category like '%fiction%' ").show(10,False)

# SQL query to add a new column
spark.sql("select distinct book_title from book").withColumn("price",lit(0)).show()

#SQL query to add multiple columns
spark.sql("select distinct book_title from book")\
      .withColumn("price",lit(0))\
      .withColumn("cover",lit("unknown"))\
      .withColumn("pages",lit(0)).show()

# SQL query to find average rating of each book
spark.sql("select book_title, round(avg(rating),2) as avg_rating from book group by book_title").show()

# To add a new column named popularity based on the rating
ds=spark.sql("select book_title, round(avg(rating),2) as avg_rating from book group by book_title")
ds.withColumn("popularity",F.when(ds["avg_rating"]>=7.0,"popular")\
              .otherwise("unpopular")).show(30)

"""# MACHINE LEARNING - RECOMMENDATION SYSTEM

"""

# Importing spark ML libraries
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml.recommendation import ALS
from pyspark.ml.feature import IndexToString
from pyspark.sql.functions import lit

# Selecting only the required features for building recommendation system
data=df1.select('user_id','rating','book_title','book_author')
data.na.drop()

# Total count of the data records
data.count()

# Creating an ID for each book
from pyspark.ml.feature import StringIndexer
indexer=StringIndexer(inputCol='book_title',outputCol='book_id')
indexed=indexer.fit(data).transform(data)
indexed.show(5)

#Splitting of training and test data
train_data, test_data = indexed.randomSplit([0.8, 0.2])

# Building of recommendation model using ALS
rec=ALS( maxIter=10,regParam=0.01,userCol='user_id',itemCol='book_id',\
        ratingCol='rating',nonnegative=True,coldStartStrategy="drop")

# Fitting the model to the train data
rec_model=rec.fit(train_data)

# Displaying the predicted ratings value
predicted_ratings=rec_model.transform(test_data)
predicted_ratings.show(5)

# Evaluating the model performance on predicting the rating
evaluator=RegressionEvaluator(metricName='rmse',predictionCol='prediction',labelCol='rating')
rmse=evaluator.evaluate(predicted_ratings)
print(rmse)

# Selecting a particular user for viewing their recommendations
user_subset=indexed.select("user_id","book_id","rating").where(indexed.user_id==8)
user_subset.show()

# Recommendations for the user specified above
user_rec=rec_model.recommendForUserSubset(user_subset,5)
user_rec.show(3,False)

# Displaying the recommended book names from the book id
for row in user_rec.collect():
    userId = row["user_id"]
    recommendations = row["recommendations"]
    bookIds = [recommendation["book_id"] for recommendation in recommendations]
    bookNames = indexed.filter(indexed["book_id"].isin(bookIds)).select("book_title").distinct().rdd.map(lambda r: r[0]).collect()
    print(f"User {userId}: Recommended Books - {bookNames}")

# Selecting a particular book for viewing the recommendations
item_subset = indexed.select("user_id","book_id","rating").where(indexed.book_id == 3868)
item_subset.show(2)

# Recommended users fot the above mentioned book
item_rec=rec_model.recommendForItemSubset(item_subset, 5)
for row in item_rec.collect():
    bookId = row["book_id"]
    recommendations = row["recommendations"]
    userIds = [recommendation["user_id"] for recommendation in recommendations]
    bookNames = indexed.filter(indexed["user_id"].isin(userIds)).select("user_id").distinct().rdd.map(lambda r: r[0]).collect()
    print(f"Book {bookId}: Recommended Users - {bookNames}")

"""The above recommendation model can provide both user based recommendation and book or item based recommendation. Following is the sample recommendations found from the model.

1. For user 8 the recommended books are:
  
  - Secret Ceremonies: A Mormon Woman's Intimate Diary of Marriage and Beyond

  - The Trade
  
  - Moo Baa La La La
  
  - The Women's Room
  
  - I'M Not Anti-Business
  
  - I'M Anti-Idiot-Dilbert

2. For the book 3868 the recommended users are:

  - 250533
  
  - 151800
  
  - 211176
  
  - 131182
  
  - 85833
"""